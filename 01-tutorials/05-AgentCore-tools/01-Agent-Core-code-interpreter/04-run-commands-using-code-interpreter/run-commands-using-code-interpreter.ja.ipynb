{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Bedrock AgentCore コード インタープリターでコマンドを実行する - チュートリアル\n\nこのチュートリアルでは、Amazon Bedrock AgentCore コード インタープリターを使用してコマンド (シェルと AWS CLI) を実行する方法を示します。AWS サービスと対話し、特に S3 操作に焦点を当てます。以下の手順を説明します。\n\n1. コード インタープリターの作成\n2. コード インタープリター セッションの開始\n3. コマンドの実行 (シェルと AWS CLI)\n5. S3 操作の実行 (バケットの作成、オブジェクトのコピー、バケット オブジェクトの一覧表示)\n6. クリーンアップ (セッションの停止とコード インタープリターの削除)\n\n## 前提条件\n- Bedrock AgentCore コード インタープリターにアクセスできる AWS アカウント\n- コード インタープリター リソースを作成および管理するための必要な IAM 権限\n- S3 操作を実行するための必要な IAM 権限\n- 必要な Python パッケージがインストールされている (boto3 と bedrock-agentcore を含む)\n\n## IAM 実行ロールには、以下の IAM ポリシーが添付されている必要があります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~ {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"bedrock-agentcore:CreateCodeInterpreter\",\n                \"bedrock-agentcore:StartCodeInterpreterSession\",\n                \"bedrock-agentcore:InvokeCodeInterpreter\",\n                \"bedrock-agentcore:StopCodeInterpreterSession\",\n                \"bedrock-agentcore:DeleteCodeInterpreter\",\n                \"bedrock-agentcore:ListCodeInterpreters\",\n                \"bedrock-agentcore:GetCodeInterpreter\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:log-group:/aws/bedrock-agentcore/code-interpreter*\"\n        }\n    ]\n}\n\n日本語訳:\n~~~ {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"許可\",\n            \"Action\": [\n                \"bedrock-agentcore:CreateCodeInterpreter\",\n                \"bedrock-agentcore:StartCodeInterpreterSession\",\n                \"bedrock-agentcore:InvokeCodeInterpreter\",\n                \"bedrock-agentcore:StopCodeInterpreterSession\",\n                \"bedrock-agentcore:DeleteCodeInterpreter\",\n                \"bedrock-agentcore:ListCodeInterpreters\",\n                \"bedrock-agentcore:GetCodeInterpreter\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"許可\",\n            \"Action\": [\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\"\n            ],\n            \"Resource\": \"arn:aws:logs:*:*:log-group:/aws/bedrock-agentcore/code-interpreter*\"\n        }\n    ]\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IAM実行ロールには、以下の信頼ポリシーも付与する必要があります。 bedrock-agentcore.amazonaws.com を信頼ポリシーに含めることで、Bedrock Agent サービス自体がこの IAM ロールを引き受け、あなたに代わって操作 (Amazon S3 など) を実行できるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"許可\",\n            \"Principal\": {\n                \"AWS\": \"arn:aws:iam::558228106740:root\",\n                \"Service\": [\n                    \"bedrock-agentcore.amazonaws.com\"\n                ]\n            },\n            \"Action\": \"sts:AssumeRole\",\n            \"Condition\": {}\n        }\n    ]\n}\n```\n\n日本語訳:\nバージョンは 2012-10-17 です。ステートメントには以下の内容が含まれています。\n\n効果は「許可」です。\nプリンシパルには、AWS アカウント ID 558228106740 のルートユーザーと、\"bedrock-agentcore.amazonaws.com\" サービスが含まれています。\nアクションは \"sts:AssumeRole\" です。\n条件はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、このチュートリアルで説明されている s3 操作を実行するには、AmazonS3FullAccess IAM ポリシーを IAM 実行ロールに付与する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動作の仕組み\n\nコード実行サンドボックスは、コード インタプリター、シェル、ファイル システムを備えた分離された環境を作成することで、エージェントがユーザーのクエリを安全に処理できるようにします。大規模言語モデルがツールの選択を支援した後、コードがこのセッション内で実行され、その結果がユーザーまたはエージェントに合成のために返されます。\n\n![architecture local](code-interpreter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境のセットアップ\n\nまず、必要なライブラリを import しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:38:33.000173Z",
     "start_time": "2025-07-13T12:38:32.995251Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from bedrock_agentcore.tools.code_interpreter_client import code_session, CodeInterpreter\n",
    "from bedrock_agentcore._utils import endpoints\n",
    "import time\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 設定変数\n\nコード インタープリターと S3 操作に必要な設定変数を設定します。また、コード インタープリターに渡す IAM 実行ロールを提供しています。これにより、コード インタープリターは、このロールを引き受けて他の AWS リソースにアクセスできます。このロールには、上記のように S3 の許可が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:56:35.843558Z",
     "start_time": "2025-07-13T12:56:35.834789Z"
    }
   },
   "outputs": [],
   "source": [
    "# 設定のセットアップ\n\n日本語訳:\n\n# 設定のセットアップ\n\n次の手順に従って、アプリケーションの設定を行ってください。\n\n1. config.py ファイルを開き、以下の変数を設定します。\n\n API_KEY = \"your_api_key_here\"\n SECRET_KEY = \"your_secret_key_here\"\n\n2. データベースの接続設定を行います。settings.py ファイルを開き、以下の行を編集してください。\n\n DATABASES = {\n     'default': {\n         'ENGINE': 'django.db.backends.postgresql',\n         'NAME': 'your_db_name',\n         'USER': 'your_db_user',\n         'PASSWORD': 'your_db_password',\n         'HOST': 'localhost',\n         'PORT': '5432',\n     }\n }\n\n3. 次のコマンドを実行して、マイグレーションを適用します。\n\n $ python manage.py migrate\n\n4. 開発用サーバーを起動するには、次のコマンドを実行します。\n\n $ python manage.py runserver\n\nアプリケーションは now http://127.0.0.1:8000/ で実行されています。\nexecution_role_arn = \"<execution-role-arn>\"\nunique_bucket_name = f\"amzn-bucket-{int(time.time())}\"\ns3_path = f\"s3://{unique_bucket_name}\"\n\nregion = \"us-west-2\"\n\n#local file that we will upload to Code interpreter and then to an S3 bucket\n\n日本語訳:\n# Code interpreter に アップロードし、その後 S3 バケットに アップロードするローカルファイル\nlocal_file = \"samples/stats.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. エンドポイントの設定\n\nboto3 クライアントを作成するために、データプレーンとコントロールプレーンの両方のエンドポイントを構成する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:56:39.350883Z",
     "start_time": "2025-07-13T12:56:39.346623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure endpoints\ndata_plane_endpoint = endpoints.get_data_plane_endpoint(region)\ncontrol_plane_endpoint = endpoints.get_control_plane_endpoint(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AWS クライアントの作成\n\nコントロールプレーンとデータプレーンの両方の操作用に、boto3 クライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:56:43.741864Z",
     "start_time": "2025-07-13T12:56:43.720200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create boto3 clients\n\n日本語訳:\nboto3 クライアントを作成します。\n\nimport boto3\n\nec2 = boto3.client('ec2')\ns3 = boto3.resource('s3')\n\n# List EC2 instances\ninstances = ec2.describe_instances()\nfor reservation in instances['Reservations']:\n    for instance in reservation['Instances']:\n        instance_id = instance['InstanceId']\n        instance_type = instance['InstanceType']\n        print(f'Instance ID: {instance_id}, Type: {instance_type}')\n\n# List S3 buckets\nfor bucket in s3.buckets.all():\n    print(f'Bucket Name: {bucket.name}')\ncp_client = boto3.client(\"bedrock-agentcore-control\", \n                        region_name=region,\n                        endpoint_url=control_plane_endpoint)\n\ndp_client = boto3.client(\"bedrock-agentcore\", \n                        region_name=region,\n                        endpoint_url=data_plane_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. コードインタープリターの作成\n\n特定の構成パラメーターを使用してコードインタープリターインスタンスを作成します。\n\nコードインタープリターを構成する際、ネットワーク設定 (Sandbox、Public、または VPC)、依存関係の構成、セキュリティ設定を選択でき、また、IAM ランタイムロールを通じてコードインタープリターがアクセスできる AWS リソースを定義するアクセス許可を設定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:56:51.810308Z",
     "start_time": "2025-07-13T12:56:50.250747Z"
    }
   },
   "outputs": [],
   "source": [
    "# コードインタープリターを作成\n\n日本語訳:\n\n# コードインタープリターを作成\n\nimport sys\n\ndef eval_expr(expr):\n    \"\"\"\n    eval_expr(expr) は、与えられた expr を評価し、その結果を返します。\n    expr は、数値、変数、演算子 (+、-、*、/)、および丸括弧で構成される文字列です。\n    \"\"\"\n    # ここにコードを記述します。\n\ndef test_eval_expr():\n    \"\"\"\n    eval_expr の単体テストを行います。\n    \"\"\"\n    # ここにテストコードを記述します。\n    print('すべてのテストが完了しました。')\n\nif __name__ == '__main__':\n    test_eval_expr()\nunique_name = f\"s3InteractionEnv_{int(time.time())}\"\ninterpreter_response = cp_client.create_code_interpreter(\n    name=unique_name,\n    description=\"Environment for S3 file operations\",\n    executionRoleArn=execution_role_arn,\n    networkConfiguration={\n        'networkMode': 'PUBLIC'\n    }\n)\ninterpreter_id = interpreter_response[\"codeInterpreterId\"]\nprint(f\"Created interpreter: {interpreter_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. セッションの開始\n\nコード インタープリター内でセッションを作成し、コードを実行します。\n\n日本語訳:\n## 6. セッションの開始\n\nコード インタープリターの中で セッションを作成し、コードを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:57:00.097783Z",
     "start_time": "2025-07-13T12:56:57.832645Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start session\n\nセッションを開始します。\n\n以下のテキストを英語から日本語に翻訳します。半角英数字の前後には半角スペースを挿入し、コード、コマンド、変数名、関数名などの技術的な用語はそのまま残します。\nsession_response = dp_client.start_code_interpreter_session(\n    codeInterpreterIdentifier=interpreter_id,\n    name=\"s3InteractionSession\",\n    sessionTimeoutSeconds=900\n)\nsession_id = session_response[\"sessionId\"]\nprint(f\"Created session: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ツール実行のためのヘルパー関数\n\nコードインタープリターツールの呼び出しを簡素化するためのユーティリティ関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:57:02.281362Z",
     "start_time": "2025-07-13T12:57:02.277560Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    response = dp_client.invoke_code_interpreter(\n",
    "        codeInterpreterIdentifier=interpreter_id,\n",
    "        sessionId=session_id,\n",
    "        name=tool_name,\n",
    "        arguments=arguments\n",
    "    )\n",
    "    for event in response[\"stream\"]:\n",
    "        return json.dumps(event[\"result\"], indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. テストコードの実行\n\n### 8.1 簡単な Hello World の例でコード インタープリターをテストします。\n\n日本語訳:\n## 8. コードの実行をテストする\n\n### 8.1 簡単な Hello World の例で、コード インタプリタをテストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:57:05.784367Z",
     "start_time": "2025-07-13T12:57:05.429150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test code execution\n\nテストコードの実行\n\n以下のように、 `run_test()` 関数を呼び出すことで、テストコードを実行できます。\n\n```python\nif __name__ == \"__main__\":\n    run_test()\n```\n\nこの関数は、 `tests/` ディレクトリ内のすべての `.py` ファイルを検索し、それらのファイル内の `TestCase` クラスを実行します。テストの結果は、標準出力に出力されます。\n\nテストが失敗した場合は、 `pytest` を使用して、より詳細な情報を取得することができます。 `pytest` は、 Python の単体テストフレームワークです。以下のコマンドを実行すると、 `pytest` がインストールされます。\n\n```\npip install pytest\n```\n\nその後、以下のコマンドを実行すると、 `tests/` ディレクトリ内のすべてのテストが実行されます。\n\n```\npytest tests/\n```\n# S3 操作\n\n日本語訳:\n\nAmazon S3 は、データを任意の場所から安全に保存および取得できるようにするオブジェクトストレージサービスです。S3 は、99.999999999% の耐久性を備えており、データを安全に保存できます。\n\nS3 では、バケットを使用してデータを格納します。バケットは、オブジェクトの格納と管理のためのコンテナです。各オブジェクトは、バケット内に格納されます。\n\nS3 の主な操作は次のとおりです。\n\n1. バケットの作成: `aws s3 mb s3://bucket-name`\n2. オブジェクトのアップロード: `aws s3 cp file.txt s3://bucket-name`\n3. オブジェクトのダウンロード: `aws s3 cp s3://bucket-name/file.txt file.txt`\n4. オブジェクトの一覧表示: `aws s3 ls s3://bucket-name`\n5. バケットの削除: `aws s3 rb s3://bucket-name`\n\nS3 は、データの耐久性、可用性、セキュリティを確保するための多くの機能を提供しています。アクセス制御リスト (ACL) やバケットポリシーを使用して、オブジェクトへのアクセスを制御できます。また、バージョニングを有効にすると、オブジェクトの以前のバージョンを保持できます。さらに、ライフサイクルポリシーを設定して、オブジェクトの有効期限を管理できます。\nprint(\"executing shell command \\n\")\ncommand_response = call_tool(\"executeCommand\",\n                              {\"command\": \"echo 'Hello World'\"})\nprint(f\"command result: {command_response}\")\n\n# Parse and display results\n\n# 結果を解析して表示する\n\nresults = parse_data( raw_data )\nfor result in results:\n    print( f\"Name: { result['name'] }\" )\n    print( f\"Score: { result['score'] }\" )\n    print( )  # 空行を挿入\n\n# 結果を JSON として保存\noutput_json = json.dumps( results )\nwith open( \"results.json\", \"w\" ) as f:\n    f.write( output_json )\n\nprint( \"Done!\" )\ncommand_results = json.loads(command_response)\nprint(command_results['structuredContent']['stdout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 次に、boto3 を PIP を使ってサンドボックスにインストールしましょう\n\n日本語訳:\n8.2 次に、サンドボックス内で PIP を使って boto3 をインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T12:58:00.949276Z",
     "start_time": "2025-07-13T12:57:59.563316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test code execution\n\nテストコードの実行\n\n以下のように、 `run_test()` 関数を呼び出すことで、テストコードを実行できます。\n\n```python\nif __name__ == \"__main__\":\n    run_test()\n```\n\nこの関数は、 `tests/` ディレクトリ内のすべての `.py` ファイルを検索し、それらのファイル内の `TestCase` クラスを実行します。テストの結果は、標準出力に出力されます。\n\nテストが失敗した場合は、 `pytest` を使用してデバッグすることをお勧めします。 `pytest` は、より詳細な出力とデバッグ機能を提供してくれます。\n\n```bash\npip install pytest\npytest tests/\n```\n# S3 操作\n\n日本語訳:\n\nAmazon S3 は、データを任意の場所から安全に保存および取得できるようにするオブジェクトストレージサービスです。S3 を使用すると、いつでもウェブサービスからデータを取得できます。\n\nS3 では、データはバケットに格納されます。バケットは、オブジェクトを格納するための S3 のコンテナです。オブジェクトは、ファイルとそのファイルに関連付けられたメタデータの集合です。\n\nS3 では、次の操作を実行できます。\n\n- 新しいバケットを作成する: `create_bucket` 関数を使用します。\n- オブジェクトをアップロードする: `put_object` 関数を使用します。\n- オブジェクトをダウンロードする: `get_object` 関数を使用します。\n- オブジェクトを削除する: `delete_object` 関数を使用します。\n- バケットを削除する: `delete_bucket` 関数を使用します。\n\nこれらの操作の詳細については、AWS のドキュメントを参照してください。\nprint(\"executing shell command \\n\")\ncommand_response = call_tool(\"executeCommand\",\n                              {\"command\": \"pip install boto3\"})\n\n# Parse and display results\n\n# 結果を解析して表示する\n\nresults = parse_data(data_file)  # data_file からデータを解析\n\nprint(\"Total records: \", len(results))  # 総レコード数を出力\n\nfor result in results:\n    print(f\"Name: {result['name']}, Score: {result['score']}\")  # 各レコードの name と score を出力\ncommand_results = json.loads(command_response)\nprint(command_results['structuredContent']['stdout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ファイル操作とS3との対話によるコマンド実行\n\n#### 9.1 ローカルファイルをサンドボックスに書き込む\n\n日本語訳:\nあなたは翻訳の専門家です。以下のテキストを英語から日本語に翻訳してください。\n半角英数字の前後には半角スペースを挿入する。コードやコマンド、変数名、関数名などの技術的な用語は翻訳せず、そのまま残してください。\n\n翻訳するテキスト:\n```\n!echo \"hello world\" > hello.txt\n```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:02:22.397060Z",
     "start_time": "2025-07-13T13:02:22.010485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write file to sandbox\n\nsandbox に ファイルを書き込む\n\nimport os\n\ndef write_file(filename, contents):\n    \"\"\"\n    filename (str): 書き込むファイルの名前\n    contents (str): ファイルに書き込む内容\n    \"\"\"\n    with open(os.path.join('/sandbox', filename), 'w') as f:\n        f.write(contents)\n\n# 使用例\nwrite_file('hello.txt', 'Hello, World!')\nprint(\"Writing file to sandbox\")\ntry:\n    with open(local_file, 'r', encoding='utf-8') as local_file_content:\n        local_file_content = local_file_content.read()\nexcept FileNotFoundError:\n    print(f\"Error: The file '{local_file}' was not found.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\nfiles_to_create = [{\n        \"path\": \"stats.py\",\n        \"text\": local_file_content\n}]\nwrite_files_response = call_tool(\"writeFiles\", {\"content\": files_to_create})\nprint(f\"write files result: {write_files_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 コード インタープリターを使用して S3 バケットを作成する\n\n日本語訳:\n\nこの項では、AWS SDK を使用して S3 バケットを作成する方法を説明します。以下の手順に従ってください。\n\n1. まず、 `aws_s3` リソースを使用して新しい S3 バケットを作成します。\n\n```python\nresource = boto3.resource('s3')\nbucket = resource.Bucket('my-bucket-name')\nbucket.create(\n    CreateBucketConfiguration={\n        'LocationConstraint': 'ap-northeast-1'\n    }\n)\n```\n\n2. バケットが正常に作成されたことを確認するには、 `bucket.name` と `bucket.creation_date` を出力します。\n\n```python\nprint(bucket.name)\nprint(bucket.creation_date)\n```\n\n3. オプションで、バケットにオブジェクトをアップロードすることもできます。 `bucket.upload_file()` メソッドを使用して、ローカル ファイルをバケットにアップロードします。\n\n```python\nbucket.upload_file('/path/to/local/file', 'object-name')\n```\n\n4. バケットの内容を一覧表示するには、 `bucket.objects.all()` を使用します。\n\n```python\nfor obj in bucket.objects.all():\n    print(obj.key)\n```\n\nこれで、Python コードを使用して S3 バケットを作成し、オブジェクトをアップロードおよび一覧表示する方法がわかりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:00:44.731145Z",
     "start_time": "2025-07-13T13:00:42.661104Z"
    }
   },
   "outputs": [],
   "source": [
    "# S3 Operations\n\n日本語訳:\n\nAmazon S3 は、データを任意の場所から安全に保存および取得できるオブジェクトストレージサービスです。S3 では、データを 1 つ以上の バケット に格納します。バケットは、データを格納するための コンテナ のようなものです。\n\nS3 では、以下の操作を実行できます。\n\n- バケットの作成\n- データのアップロード\n- アクセス許可の設定\n- データの取得\n- データの削除\n\nS3 には、データを保存するための複数の ストレージクラス があります。ストレージクラスは、データのアクセス頻度に基づいて選択できます。頻繁にアクセスするデータには、高速で低コストの S3 Standard を使用します。頻繁にアクセスしないデータには、低コストの S3 Glacier を使用します。\n\nS3 では、データの転送料金、ストレージ料金、その他の料金が発生します。料金は、使用するリージョン、ストレージクラス、データ転送量などによって異なります。\n\nS3 は、高い可用性、耐久性、セキュリティを備えています。データは、複数の施設に冗長的に保存されます。また、データの暗号化、アクセス制御、監査ログなどの機能により、データの保護が可能です。\nprint(\"\\nCreating S3 bucket\")\ncreate_s3_response = call_tool(\"executeCommand\",\n                              {\"command\": f\"aws s3 mb {s3_path} --region {region}\"})\nprint(f\"create result: {create_s3_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 Upload file from code interpreter by running command to the S3 Bucket (created above)\n\n日本語訳:\n\n#### 9.3 コード インタープリターから実行コマンドによって、上記で作成した S3 バケットにファイルをアップロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:02:31.834784Z",
     "start_time": "2025-07-13T13:02:30.724996Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nUploading file to S3\")\n",
    "upload_to_s3_response = call_tool(\"executeCommand\",\n",
    "                                 {\"command\": f\"aws s3 cp {files_to_create[0]['path']} {s3_path}\"})\n",
    "print(f\"upload result: {upload_to_s3_response}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4 コード インタープリターでコマンドを実行して S3 バケットからファイルを一覧表示する\n\n日本語訳:\n\nコード インタープリターでコマンドを実行することにより、S3 バケットからファイルを一覧表示できます。以下の `aws s3 ls` コマンドを使用して、バケット内のファイルとプレフィックス (ディレクトリのようなもの) を一覧表示します。\n\n```\naws s3 ls s3://{{ bucket }}/ --recursive --human-readable --summarize\n```\n\nこのコマンドは、指定された S3 バケット内のすべてのファイルとプレフィックスを再帰的に一覧表示します。`--human-readable` フラグにより、ファイルサイズが読みやすい形式で表示されます。`--summarize` フラグを使用すると、バケットの合計ファイル数とサイズの概要が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:02:35.644224Z",
     "start_time": "2025-07-13T13:02:34.539568Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nListing files in S3\")\n",
    "list_s3_response = call_tool(\"executeCommand\",\n",
    "                            {\"command\": f\"aws s3 ls {s3_path}\"})\n",
    "print(f\"list result: {list_s3_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. リソースのクリーンアップ\n\nセッションを停止し、インタープリターを削除することでリソースをクリーンアップします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:04:38.694932Z",
     "start_time": "2025-07-13T13:04:31.545319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup\n\n日本語訳:\n\nこの手順は、不要なファイルやディレクトリを削除して、システムをクリーンアップするためのものです。\n\n1. 一時ファイルを削除するには、次のコマンドを実行します: `rm -rf /tmp/*`\n\n2. キャッシュをクリアするには、次のコマンドを実行します: `sudo apt-get clean`\n\n3. 古いカーネルイメージを削除するには、次のコマンドを実行します: `sudo apt-get autoremove --purge`\n\n4. 不要なパッケージを削除するには、次のコマンドを実行します: `sudo apt-get autoremove`\n\n5. 最後に、ディスクの空き領域を確保するために、次のコマンドを実行します: `sudo apt-get autoclean`\n\nシステムがクリーンアップされ、ディスク領域が解放されました。\nprint(\"Cleaning up session and interpreter\")\ndp_client.stop_code_interpreter_session(\n    codeInterpreterIdentifier=interpreter_id,\n    sessionId=session_id\n)\nprint(\"Session stopped successfully\")\n\ncp_client.delete_code_interpreter(codeInterpreterId=interpreter_id)\nprint(\"Interpreter deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}