{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52dc9b17-1182-44b3-bebf-ae2f508675d3",
   "metadata": {},
   "source": [
    "# AgentCore ランタイムでの大規模マルチモーダルペイロードの処理\n",
    "\n",
    "## 概要\n",
    "\n",
    "このチュートリアルでは、Amazon Bedrock AgentCore ランタイムが Excel ファイルや画像などのマルチモーダルコンテンツを含む最大 100MB のペイロードをどのように処理するかを説明します。AgentCore ランタイムは、リッチメディアコンテンツや大規模データセットをシームレスに処理するように設計されています。\n",
    "\n",
    "### チュートリアルの詳細\n",
    "\n",
    "|情報| 詳細|\n",
    "|:--------------------|:---------------------------------------------------------------------------------|\n",
    "| チュートリアルの種類       | 大規模ペイロード & マルチモーダル処理|\n",
    "| エージェントの種類          | 単一         |\n",
    "| エージェントフレームワーク   | Strands Agents |\n",
    "| LLM モデル           | Anthropic Claude Sonnet 4 |\n",
    "| チュートリアルのコンポーネント | 大規模ファイル処理、画像分析、Excel データ処理 |\n",
    "| チュートリアルの分野   | データ分析 & マルチモーダル AI                                                   |\n",
    "| 例の複雑さ  | 中級                                                     |\n",
    "| 使用 SDK            | Amazon BedrockAgentCore Python SDK|\n",
    "\n",
    "### 主な機能\n",
    "\n",
    "* **大規模ペイロードのサポート**: 最大 100MB のファイルを処理\n",
    "* **マルチモーダル処理**: Excel ファイル、画像、テキストを同時に処理\n",
    "* **データ分析**: 構造化データと視覚的コンテンツから洞察を抽出\n",
    "* **Base64 エンコーディング**: JSON ペイロードを通じたバイナリデータの安全な送信"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "* Python 3.10+\n",
    "* AWS 認証情報が設定済み\n",
    "* Docker が実行中\n",
    "* テスト用のサンプル Excel ファイルと画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv add -r requirements.txt --active\n",
    "#!uv add openpyxl --active\n",
    "\n",
    "import os\n",
    "os.environ[\"AWS_PROFILE\"] = \"cline2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## サンプルデータファイルの作成\n",
    "\n",
    "大きなペイロード処理を実演するために、サンプルの Excel ファイルと画像ファイルを作成しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# サンプル販売データを含む大きな Excel ファイルを作成する\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Date': pd.date_range('2023-01-01', periods=1000, freq='h'),\n",
    "    'Product': np.random.choice(['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y'], 1000),\n",
    "    'Sales': np.random.randint(1, 1000, 1000),\n",
    "    'Revenue': np.random.uniform(10.0, 5000.0, 1000),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], 1000),\n",
    "    'Customer_ID': np.random.randint(1000, 9999, 1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('large_sales_data.xlsx', index=False)\n",
    "\n",
    "# サンプルチャート画像を作成する\n",
    "img = Image.new('RGB', (600, 500), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# 簡単な棒グラフを描画する\n",
    "products = ['Widget A', 'Widget B', 'Widget C', 'Gadget X', 'Gadget Y']\n",
    "values = [250, 180, 320, 150, 280]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "\n",
    "max_value = max(values)\n",
    "bar_width = 120\n",
    "start_x = 100\n",
    "\n",
    "for i, (product, value, color) in enumerate(zip(products, values, colors)):\n",
    "    x = start_x + i * (bar_width + 20)\n",
    "    height = int((value / max_value) * 400)\n",
    "    y = 500 - height\n",
    "    \n",
    "    # Draw bar\n",
    "\n",
    "# バーを描画する\n",
    "    draw.rectangle([x, y, x + bar_width, 500], fill=color)\n",
    "    \n",
    "    # ラベルを追加する（フォントなしの簡略版）\n",
    "    draw.text((x + 10, 510), product[:8], fill='black')\n",
    "    draw.text((x + 10, y - 20), str(value), fill='black')\n",
    "\n",
    "draw.text((300, 50), 'Sales Performance by Product', fill='black')\n",
    "img.save('sales_chart.png')\n",
    "\n",
    "# ファイルサイズの確認\n",
    "excel_size = os.path.getsize('large_sales_data.xlsx') / (1024 * 1024)  # MB\n",
    "\n",
    "# MB\n",
    "image_size = os.path.getsize('sales_chart.png') / (1024 * 1024)  # MB\n",
    "\n",
    "# MB\n",
    "\n",
    "print(f\"Excel file size: {excel_size:.2f} MB\")\n",
    "print(f\"Image file size: {image_size:.2f} MB\")\n",
    "print(f\"Total payload size: {excel_size + image_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-code",
   "metadata": {},
   "source": [
    "## マルチモーダルエージェントの作成\n",
    "\n",
    "大きなペイロードから Excel ファイルと画像の両方を処理できるエージェントを作成しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multimodal_data_agent.py\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# モデルとエージェントを初期化する\n",
    "#model_id = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    "    max_tokens=16000\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"\n",
    "    あなたは大きな Excel ファイルや画像を処理できるデータ分析アシスタントです。\n",
    "    マルチモーダルデータが与えられた場合、構造化データと視覚的コンテンツの両方を分析し、\n",
    "    両方のデータソースを組み合わせた包括的な洞察を提供します。\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def multimodal_data_processor(payload, context):\n",
    "    \"\"\"\n",
    "    Excel データと画像を含む大規模なマルチモーダルペイロードを処理します。\n",
    "    \n",
    "    Args:\n",
    "        payload: プロンプト、excel_data（base64）、image_data（base64）を含みます\n",
    "        context: ランタイムコンテキスト情報\n",
    "    \n",
    "    Returns:\n",
    "        str: 両方のデータソースからの分析結果\n",
    "    \"\"\"\n",
    "    prompt = payload.get(\"prompt\", \"Analyze the provided data.\")\n",
    "    excel_data = payload.get(\"excel_data\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    print(f\"=== Large Payload Processing ===\")\n",
    "    print(f\"Session ID: {context.session_id}\")\n",
    "    \n",
    "    if excel_data:\n",
    "        print(f\"Excel data size: {len(excel_data) / 1024 / 1024:.2f} MB\")\n",
    "    if image_data:\n",
    "        print(f\"Image data size: {len(image_data) / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"Excel data {excel_data}\")\n",
    "    print(f\"Image data {image_data}\")\n",
    "    print(f\"=== Processing Started ===\")\n",
    "    # base64 をバイトにデコードする\n",
    "    excel_bytes = base64.b64decode(excel_data)\n",
    "    # base64 をバイトにデコードする\n",
    "    image_bytes = base64.b64decode(image_data)\n",
    "    \n",
    "    # データコンテキストを強化したプロンプト\n",
    "    enhanced_prompt = f\"\"\"{prompt}\n",
    "    両方のデータソースを分析して、洞察を提供してください。\n",
    "    \"\"\"\n",
    "    \n",
    "    response = agent(\n",
    "        [{\n",
    "            \"document\": {\n",
    "                \"format\": \"xlsx\",\n",
    "                \"name\": \"excel_data\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": excel_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": image_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"text\": enhanced_prompt\n",
    "        }]\n",
    "    )\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-infrastructure",
   "metadata": {},
   "source": [
    "## インフラストラクチャのセットアップとエージェントのデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 現在のノートブックのディレクトリを取得する\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "# utils.py の場所に移動する\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# sys.path に追加する\n",
    "sys.path.insert(0, utils_dir)\n",
    "\n",
    "from utils import create_agentcore_role\n",
    "\n",
    "agent_name = \"multimodal_data_agent\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"multimodal_data_agent.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "\n",
    "launch_result = agentcore_runtime.launch(auto_update_on_conflict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-for-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(f\"Deployment status: {status}\")\n",
    "\n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-large-payloads",
   "metadata": {},
   "source": [
    "## 大規模なマルチモーダルペイロードのテスト\n",
    "\n",
    "ここでは、Excel データと画像の両方を含む大規模なペイロードでエージェントをテストしてみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import uuid\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# ファイルを base64 にエンコードする\n",
    "with open('large_sales_data.xlsx', 'rb') as f:\n",
    "    excel_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "with open('sales_chart.png', 'rb') as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "# 大きなペイロードを作成する\n",
    "large_payload = {\n",
    "    \"prompt\": \"Analyze the sales data from the Excel file and correlate it with the chart image. Provide insights on sales performance and trends.\",\n",
    "    \"excel_data\": excel_base64,\n",
    "    \"image_data\": image_base64\n",
    "}\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "print(f\"📊 Processing large multi-modal payload...\")\n",
    "print(f\"📋 Session ID: {session_id}\")\n",
    "print(f\"📄 Excel size: {len(excel_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"🖼️ Image size: {len(image_base64) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"📦 Total payload: {len(json.dumps(large_payload)) / 1024 / 1024:.2f} MB\\n\")\n",
    "\n",
    "# 大きなペイロードでエージェントを呼び出す\n",
    "invoke_response = agentcore_runtime.invoke(\n",
    "    large_payload,\n",
    "    session_id=session_id\n",
    ")\n",
    "\n",
    "# 修正部分: バイトを連結してからデコードする\n",
    "response_bytes = b''\n",
    "for r in invoke_response['response']:\n",
    "    response_bytes += r\n",
    "\n",
    "try:\n",
    "    final_response = response_bytes.decode(\"utf-8\")\n",
    "    response_data = json.loads(final_response)\n",
    "    display(Markdown(response_data))\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"デコードエラー: {e}\")\n",
    "    print(\"別の方法でデコードを試みます...\")\n",
    "    \n",
    "    # エラー処理オプション1: エラーを無視して置換文字を使用\n",
    "    final_response = response_bytes.decode(\"utf-8\", errors=\"replace\")\n",
    "    try:\n",
    "        response_data = json.loads(final_response)\n",
    "        display(Markdown(response_data))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSONとして解析できません。レスポンスの形式を確認してください。\")\n",
    "        \n",
    "        # エラー処理オプション2: レスポンスの形式を確認\n",
    "        print(f\"レスポンスの型: {type(invoke_response['response'][0])}\")\n",
    "        print(f\"最初の数バイト: {invoke_response['response'][0][:20] if len(invoke_response['response']) > 0 else 'レスポンスが空です'}\")\n",
    "        \n",
    "        # バイナリデータの可能性がある場合\n",
    "        try:\n",
    "            from PIL import Image\n",
    "            import io\n",
    "            img = Image.open(io.BytesIO(response_bytes))\n",
    "            print(\"画像データとして処理します\")\n",
    "            display(img)\n",
    "        except Exception as img_error:\n",
    "            print(f\"画像として処理できません: {img_error}\")\n",
    "            \n",
    "            # 最後の手段: 生のバイトデータを保存\n",
    "            with open(f\"response_{session_id}.bin\", \"wb\") as f:\n",
    "                f.write(response_bytes)\n",
    "            print(f\"レスポンスをバイナリファイル 'response_{session_id}.bin' として保存しました\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## リソースのクリーンアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-resources",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# AWS リソースのクリーンアップ\n",
    "agentcore_control_client = boto3.client('bedrock-agentcore-control', region_name=region)\n",
    "ecr_client = boto3.client('ecr', region_name=region)\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "# AgentCore ランタイムの削除\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "# ECR リポジトリの削除\n",
    "ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# IAM ロールの削除\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "\n",
    "iam_client.delete_role(RoleName=agentcore_iam_role['Role']['RoleName'])\n",
    "\n",
    "# ローカルファイルのクリーンアップ\n",
    "os.remove('large_sales_data.xlsx')\n",
    "os.remove('sales_chart.png')\n",
    "\n",
    "print(\"✅ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "# おめでとうございます！\n",
    "\n",
    "Amazon Bedrock AgentCore Runtime で大規模なマルチモーダルペイロードの処理に成功しました！\n",
    "\n",
    "## 学んだこと：\n",
    "\n",
    "### 大規模ペイロード処理\n",
    "* **100MB サポート**： AgentCore Runtime は最大 100MB のペイロードを処理できます\n",
    "* **Base64 エンコーディング**： JSON ペイロードを通じたバイナリデータの安全な送信\n",
    "* **効率的な処理**： 大規模データ処理に最適化されたランタイム\n",
    "\n",
    "### マルチモーダル機能\n",
    "* **Excel 分析**： スプレッドシートからの構造化データの処理\n",
    "* **画像処理**： 視覚的なコンテンツやチャートの分析\n",
    "* **複合分析**： 複数のデータタイプからの洞察の相関付け\n",
    "\n",
    "### 主な利点\n",
    "* **豊富なデータ処理**： 複雑なマルチフォーマットのデータセットを処理\n",
    "* **スケーラブルなアーキテクチャ**： 大規模なワークロード向けに設計されたランタイム\n",
    "* **ツール統合**： 特殊なデータ処理のためのカスタムツール\n",
    "* **エンタープライズ対応**： 機密性の高いビジネスデータの安全な取り扱い\n",
    "\n",
    "これは、AgentCore Runtime が複数のデータモダリティを持つエンタープライズ規模のデータ処理タスクを処理する能力を示しており、複雑なビジネスインテリジェンスやデータ分析アプリケーションに最適です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
