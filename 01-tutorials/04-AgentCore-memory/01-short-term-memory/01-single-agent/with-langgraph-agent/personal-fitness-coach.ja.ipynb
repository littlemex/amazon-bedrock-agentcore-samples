{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda134cd-247d-40e4-b37f-0ab0a2d57943",
   "metadata": {},
   "source": [
    "# LangGraph with AgentCore Memory Tool (短期記憶)\n\nあなたは翻訳の専門家です。以下のテキストを英語から日本語に翻訳してください。\n半角英数字の前後には半角スペースを挿入する。コードやコマンド、変数名、関数名などの技術的な用語は翻訳せず、そのまま残してください。\n\n翻訳するテキスト:\nThe LangGraph is a graph-based memory tool that allows agents to store and retrieve information in a structured way. It is particularly useful for tasks that require maintaining context or building upon previous information.\n\n日本語訳:\nLangGraph は、グラフベースのメモリツールで、エージェントが構造化された方法で情報を保存して取り出すことができます。これは、コンテキストを維持したり、以前の情報に基づいて構築する必要があるタスクに特に役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98765432-abcd-1234-efgh-ijklmnopqrst",
   "metadata": {},
   "source": [
    "## はじめに\nこのノートブックでは、LangGraph フレームワークを使用して会話型 AI エージェントと Amazon Bedrock AgentCore Memory 機能を統合する方法を示します。単一の会話セッション内での **短期記憶** の保持に焦点を当て、明示的なコンテキスト管理なしに会話の前半で言及された情報をエージェントが想起できるようにします。\n\n## チュートリアルの詳細\n\n| 情報                | 詳細                                                                              |\n|:--------------------|:----------------------------------------------------------------------------------|\n| チュートリアルの種類 | 短期会話                                                                          |\n| エージェントのユースケース | パーソナルフィットネス                                                        |\n| エージェントフレームワーク | Langgraph                                                                       |\n| LLM モデル          | Anthropic Claude Sonnet 3                                                         |\n| チュートリアルコンポーネント | AgentCore 短期記憶、Langgraph、ツールによる記憶の取得                        |\n| 例の複雑さ          | 初級                                                                              |\n\n以下のことを学びます:\n- AgentCore Memory を使用して短期記憶のための記憶ストアを作成する\n- LangGraph を使用して構造化された記憶ワークフローを持つエージェントを作成する\n- 会話履歴の取得のためのメモリツールを実装する\n- 単一のセッション内でコンテキスト情報にアクセスし、活用する\n- 効果的な記憶の想起を通じて会話体験を向上させる\n\n### シナリオのコンテキスト\n\nこの例では、「**パーソナルフィットネスコーチ**」を作成し、会話の中で言及されたワークアウトの詳細、フィットネスの目標、身体的制限、運動の好みを覚えられるようにします。この助手は、効果的な短期記憶管理が、ユーザーに繰り返し情報を提供する必要がなく、より自然でパーソナライズされたフィットネスコーチング体験を可能にする方法を示します。\n\n## アーキテクチャ\n<div style=\"text-align:left\">\n    <img src=\"architecture.png\" width=\"65%\" />\n</div>\n\n## 前提条件\n\n- Python 3.10 以上\n- 適切な権限を持つ AWS アカウント\n- AgentCore Memory に適切な権限を持つ AWS IAM ロール\n- Amazon Bedrock モデルへのアクセス\n\n環境をセットアップして始めましょう!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6fc488-0f70-416b-a0e9-57671e0bfc7d",
   "metadata": {},
   "source": [
    "## ステップ 1: 環境設定\n必要なすべてのライブラリをインポートし、このノートブックを動作させるためのクライアントを定義しましょう。\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# クライアントの定義\nclient = None\nbucket = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e53844-5916-4470-a656-d59c64af4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41d38e-859c-4634-a5ef-624cbe6e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b4372-ac00-49a8-bcdf-916ac895b10a",
   "metadata": {},
   "source": [
    "以下が日本語訳になります。\n\nAmazon Bedrock models と AgentCore に適切な権限を持つリージョンとロールを定義してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f366c0b-b410-4fe5-8935-c330d5ce04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "region = os.getenv('AWS_REGION', 'us-west-2')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(\"agentcore-memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-a7b8-c9d0-e1f2a3b4c5d6",
   "metadata": {},
   "source": [
    "### 統合の仕組み\n\nLangGraphとAgentCore Memoryの統合には以下が含まれます。\n\n1. 短期記憶領域への会話の保存に AgentCore Memory を使用する\n2. メモリ操作を管理するための LangGraph 内の構造化されたワークフロー\n\nこのアプローチでは、記憶管理と推論を分離することで、より洗練され、メンテナンス性の高いエージェントアーキテクチャを実現しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f7df8-2904-43a7-8dfb-fdaa72e2f88e",
   "metadata": {},
   "source": [
    "## ステップ 2: メモリの作成\nこのセクションでは、AgentCore Memory SDK を使用してメモリストアを作成します。このメモリストアにより、エージェントは会話から情報を保持できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d31ed2-78db-42c1-9392-8815229a4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ea0be-5073-4990-a2b4-3c44510da3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MemoryClient(region_name=region)\n",
    "memory_name = \"FitnessCoach\"\n",
    "memory_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2c138-b452-4b2a-9730-6e41c824ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n    print(\"Creating Memory...\")\n    # Create the memory resource\n\nメモリリソースを作成します。\n\nresource \"aws_memorydb_cluster\" \"example\" {\n  cluster_name         = \"example-memorydb-cluster\"\n  node_type            = \"db.r6g.large\"\n  num_shards           = 2\n  num_replicas_per_shard = 1\n  acl_name             = aws_memorydb_acl.example.name\n  subnet_group_name    = aws_memorydb_subnet_group.example.name\n  security_group_ids   = [aws_security_group.example.id]\n  snapshot_retention_limit = 5\n  maintenance_window   = \"sun:23:00-mon:01:30\"\n\n  parameter_group_name = aws_memorydb_parameter_group.example.name\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n\nresource \"aws_memorydb_parameter_group\" \"example\" {\n  name   = \"example-memorydb-params\"\n  family = \"memorydb_redis6.2\"\n\n  parameter {\n    name  = \"maxmemory-policy\"\n    value = \"allkeys-lru\"\n  }\n}\n\nresource \"aws_memorydb_subnet_group\" \"example\" {\n  name       = \"example-memorydb-subnet-group\"\n  subnet_ids = [aws_subnet.example_1.id, aws_subnet.example_2.id]\n}\n\nresource \"aws_memorydb_acl\" \"example\" {\n  name        = \"example-memorydb-acl\"\n  user_names  = [\"default\"]\n  subnet_acls = [aws_memorydb_subnet_acl.example.id]\n}\n\nresource \"aws_memorydb_subnet_acl\" \"example\" {\n  name             = \"example-memorydb-subnet-acl\"\n  subnet_ids       = [aws_subnet.example_1.id, aws_subnet.example_2.id]\n  security_group_ids = [aws_security_group.example.id]\n}\n    memory = client.create_memory_and_wait(\n        name=memory_name,                       # この名前は、このアカウントのすべてのメモリ間で一意です\n\n日本語訳:\nこの名前は、このアカウントのすべての memories 間で一意です\n        description=\"Fitness Coach Agent\",      # Human-readable description\n\n人間が読めるように説明します。\n\n半角英数字の前後には半角スペースを挿入します。 コード や コマンド 、 変数名 、 関数名 などの技術的な用語は翻訳せず、そのまま残します。\n        strategies=[],                          # 短期記憶のための記憶戦略はありません\n\n日本語訳:\n\n短期記憶のための特別な記憶戦略はありません。短期記憶は一時的なものであり、情報は数秒から数分で忘れ去られます。したがって、重要な情報を長期記憶に移すためには、 rehearsal や elaborative encoding などの記憶戦略を使う必要があります。\n\nしかし、短期記憶の容量を最大限に活用するためには、いくつかのテクニックがあります。例えば、 chunking と呼ばれる方法では、関連する項目をグループ化することで、より多くの情報を短期記憶に保持できます。また、視覚的な手がかりを使うことも役立ちます。\n\n短期記憶は、長期記憶への入り口として機能しています。情報を短期記憶に保持し、適切な記憶戦略を使うことで、長期記憶に定着させることができるのです。\n        event_expiry_days=7,                    # Memories expire after 7 days\n\n日本語訳:\n# 7 日後にメモリが期限切れになります\n        max_wait=300,                           # 最大待機時間 (5 分) メモリ作成を待つ\n\n日本語訳:\n# メモリ作成を待つ最大時間 (5 分)\n        poll_interval=10                        # 10秒ごとにステータスを確認する\n\n日本語訳:\n10 秒ごとに status を確認します。 check、every、seconds は技術的な用語なので翻訳しませんでした。\n    )\n\n    # メモリIDを抽出して出力する\n\nmemory_id = subprocess.check_output([ 'cat', '/proc/meminfo' ])\nprint( \"Memory ID: \" + memory_id.split()[1] )\n    memory_id = memory['id']\n    logger.info(f\"Memory created successfully with ID: {memory_id}\")\nexcept ClientError as e:\n    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n        # If memory already exists, retrieve its ID\n\nメモリがすでに存在する場合は、その ID を取得します。\n        memories = client.list_memories()\n        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n        logger.info(f\"Memory already exists. Using existing memory ID: {memory_id}\")\nexcept Exception as e:\n    # メモリ作成中のエラーを処理する\n\ntry :\n    memory = create_memory ( )\nexcept MemoryError as error :\n    print ( f\"Error creating memory: { error }\" )\n    sys.exit ( 1 )\n\ntry :\n    data = load_data ( memory )\nexcept DataError as error :\n    print ( f\"Error loading data: { error }\" )\n    memory.free ( )\n    sys.exit ( 1 )\n\n# 残りの処理...\n    logger.info(f\"❌ ERROR: {e}\")\n    import traceback\n    traceback.print_exc()\n    # この名前は、このアカウントのすべてのメモリ間で一意です\n\n日本語訳:\nこの名前は、このアカウントのすべての memories 間で一意です0\n    if memory_id:\n        try:\n            client.delete_memory_and_wait(memory_id=memory_id)\n            logger.info(f\"Cleaned up memory: {memory_id}\")\n        except Exception as cleanup_error:\n            logger.info(f\"Failed to clean up memory: {cleanup_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac6fd5-6228-4a20-88c0-ae30da48cf3f",
   "metadata": {},
   "source": [
    "## ステップ 3: LangGraph エージェントの作成\nLangGraph を使ってエージェントを作成するために必要なすべてのライブラリをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2e879-0697-4157-9877-3253b135716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0914c-6af5-4242-9dec-b3f1a05a6432",
   "metadata": {},
   "source": [
    "### LangGraphエージェントの実装\n\nLangGraphを使って、メモリツールを組み込んだエージェントを作成しましょう。\n\n日本語訳:\n### LangGraph エージェントの実装\n\nこれから、メモリツールを組み込んだ エージェント を LangGraph を使って作成します。\n\n memory_tools = [\n    Tool(\n        name=\"memory\",\n        description=\"A vector memory to store and retrieve memories\",\n        func=memory.run\n    )\n]\n\n agent = LangGraphAgent.from_llm(\n    llm=OpenAI(temperature=0),\n    tools=memory_tools,\n    memory=memory,\n    verbose=True\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8672a-f5b6-43b6-b2fe-5fedc080a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(client, memory_id, actor_id, session_id):\n    以下が日本語訳になります。\n\n\"\"\"LangGraph エージェントの作成と構成\"\"\"\n    \n    # Initialize your LLM (adjust model and parameters as needed)\n\n大規模言語モデル (LLM) を初期化します (モデルとパラメーターは必要に応じて調整してください)\n    llm = ChatBedrock(\n        model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",  # or your preferred model\n\n日本語訳:\n# または好みの model\n        model_kwargs={\"temperature\": 0.1}\n    )\n    \n    @tool\n    def list_events():\n        \"\"\"最新の情報を取得する際に必要に応じて使用されるツール\"\"\" \n        events = client.list_events(\n                memory_id=memory_id,\n                actor_id=actor_id,\n                session_id=session_id,\n                max_results=10\n            )\n        return events\n        \n    \n    # Bind tools to the LLM\n\n# ツールを LLM にバインドする\n\nTo allow the LLM to interact with tools, we first need to define a list of tools and their corresponding functions. Here's an example of how we can bind the `python_repl` tool to the LLM:\n\nLLM がツールと対話できるようにするには、まず、ツールのリストとそれに対応する関数を定義する必要があります。以下は、`python_repl` ツールを LLM にバインドする例です。\n\n```python\nfrom langchain.agents import load_tools\nfrom langchain.llms import OpenAI\n\nllm = OpenAI(temperature=0)\ntools = load_tools([\"python_repl\"])\n\nfrom langchain.agents import initialize_agent\nagent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n```\n\nIn this example, we first load the `python_repl` tool from the `langchain.agents.load_tools` module. We then create an OpenAI language model instance with a temperature of 0 (deterministic output). \n\nこの例では、最初に `langchain.agents.load_tools` モジュールから `python_repl` ツールをロードしています。次に、温度 0 (決定論的な出力) の OpenAI 言語モデルインスタンスを作成しています。\n\nThe `load_tools` function returns a list of tool objects, which we pass to the `initialize_agent` function along with the LLM instance and the agent type (`zero-shot-react-description`). This creates an agent that can use the specified tools to assist with tasks.\n\n`load_tools` 関数はツールオブジェクトのリストを返し、それを LLM インスタンスとエージェントタイプ (`zero-shot-react-description`) とともに `initialize_agent` 関数に渡します。これにより、指定されたツールを使ってタスクを支援できるエージェントが作成されます。\n\nYou can then interact with the agent using the `agent.run` method, passing in a prompt or instruction:\n\n次に、`agent.run` メソッドを使ってプロンプトや指示を渡し、エージェントと対話できます。\n\n```python\nagent.run(\"Print the Fibonacci sequence up to the 10th number.\")\n```\n\nThis will execute the specified task, potentially using the loaded tools as needed.\n\nこれにより、指定されたタスクが実行され、必要に応じてロードされたツールが使用されます。\n    tools = [list_events]\n    llm_with_tools = llm.bind_tools(tools)\n    \n    # System message\n\nシステムメッセージ\n\nThe following code is used to create a new user account:\n\n以下の コード は新しいユーザーアカウントを作成するために使用されます:\n\n```\ncreate_user($username, $email, $password)\n```\n\nThis function takes three parameters:\n- `$username`: the desired username\n- `$email`: the user's email address\n- `$password`: the user's password\n\nこの関数は 3 つのパラメータを取ります:\n- `$username`: 希望のユーザー名\n- `$email`: ユーザーの メールアドレス\n- `$password`: ユーザーの パスワード\n\nIf the account is created successfully, it will return `true`. Otherwise, it will return `false` with an error message.\n\nアカウントが正常に作成された場合、`true` を返します。それ以外の場合は、エラーメッセージとともに `false` を返します。\n    system_message = \"\"\"あなたは Personal Fitness Coach 、高度なフィットネスガイダンス アシスタントです。\n                        目的:\n                        - ユーザーのフィットネス目標に基づいてワークアウト ルーティンを作成するのを支援する\n                        - ユーザーの運動の好み、制限、進捗状況を記憶する\n                        - パーソナライズされたフィットネス推奨とトレーニング プランを提供する\n                        メモリ機能:\n                        - list_events ツールを使用して最近のイベントにアクセスできる\n                        \"\"\"\n    \n    # Define the chatbot node\n\nchatbot ノードを定義します。\n\nimport random\n\nclass ChatbotNode:\n    \"\"\"\n    A chatbot node that generates random responses.\n    \"\"\"\n\n    def __init__(self, messages):\n        self.messages = messages\n\n    def get_response(self, input_text):\n        \"\"\"\n        Return a random response from the list of messages.\n        \"\"\"\n        return random.choice(self.messages)\n\n# Example usage\nmessages = [\n    \"Hello, how can I assist you today?\",\n    \"I'm an AI assistant. How may I help you?\",\n    \"What would you like to know?\",\n    \"I'll do my best to provide a helpful response.\"\n]\n\nchatbot = ChatbotNode(messages)\nuser_input = \"Hi there!\"\nresponse = chatbot.get_response(user_input)\nprint(response)\n    def chatbot(state: MessagesState):\n        raw_messages = state[\"messages\"]\n    \n        # Remove any existing system messages to avoid duplicates or misplacement\n\n日本語訳:\n# 重複や配置ミスを避けるため、既存のシステムメッセージを削除します。\n        non_system_messages = [msg for msg in raw_messages if not isinstance(msg, SystemMessage)]\n    \n        # Always ensure SystemMessage is first\n\nシステムメッセージが最初にくることを常に確認してください。\n        messages = [SystemMessage(content=system_message)] + non_system_messages\n    \n        latest_user_message = next((msg.content for msg in reversed(messages) if isinstance(msg, HumanMessage)), None)\n    \n        # Get response from model with tools bound\n\nモデルからツールをバインドした応答を取得する\n\nresponse = agent.run(query)\nprint(f' 応答: {response}')\n\n# 出力例:\n#  応答: < model_response >\n        response = llm_with_tools.invoke(messages)\n    \n        # Save conversation if applicable\n\n会話を保存する場合は以下のように処理します。\n\n1. conversation_history = [] という空のリストを用意します。\n2. 各ターンの会話を conversation_history.append({\"role\": role, \"content\": message}) のように追加していきます。ここで、role は \"system\"、\"user\"、\"assistant\" のいずれかを指定し、message には実際の発話内容を指定します。\n3. 会話を保存したい場合は、conversation_history をファイルに書き出すか、データベースに保存するなどの処理を行います。\n        if latest_user_message and response.content.strip():  # Check that response has content\n\nresponse = get_response()\nif response.content:\n    print(\"Response has content\")\nelse:\n    print(\"No content in response\")\n\n日本語訳:\n\n# レスポンスにコンテンツがあることを確認する\n\nresponse = get_response()\nif response.content:\n    print(\"レスポンスにコンテンツがあります\")\nelse:\n    print(\"レスポンスにコンテンツがありません\")\n            conversation = [\n                (latest_user_message, \"USER\"),\n                (response.content, \"ASSISTANT\")\n            ]\n            \n            # メッセージテキストが空でないことを検証する\n\n日本語訳:\n\n```python\ndef validate_messages(messages):\n    \"\"\"\n    messages は dict 型で、キーが言語コード (例: 'en'、'ja')、\n    値がその言語のメッセージ dict となっている。\n    メッセージ dict のキーがメッセージ ID、値がメッセージテキストである。\n\n    すべての言語で、すべてのメッセージテキストが空でないことを確認する。\n    空のメッセージテキストが見つかった場合は ValueError を送出する。\n    \"\"\"\n    for lang_code, lang_messages in messages.items():\n        for msg_id, msg_text in lang_messages.items():\n            if not msg_text.strip():\n                raise ValueError(f'Empty message text for {lang_code} {msg_id}')\n```\n\nこの関数は、複数の言語のメッセージテキストが含まれる `messages` dict を受け取ります。各言語のメッセージは、言語コードをキー、メッセージ ID をキーとするネストした dict で表現されています。\n\n関数内部では、すべての言語とメッセージ ID に対して、対応するメッセージテキストが空でないことを確認しています。空のメッセージテキストが見つかった場合は、言語コードとメッセージ ID を含む `ValueError` が送出されます。\n\nこの関数を使うことで、アプリケーションの国際化対応時に、誤って空のメッセージテキストが残っていないかを検証できます。\n            if all(msg[0].strip() for msg in conversation):  # 空のメッセージがないことを確認する\n\n日本語訳:\n\n空のメッセージがないことを確認するには、以下の `ensure_no_empty_messages` 関数を使用します。この関数は、メッセージの配列 `messages` を受け取り、空の文字列が含まれている場合は `ValueError` 例外を送出します。\n\n```python\ndef ensure_no_empty_messages(messages):\n    \"\"\"空のメッセージがないことを確認する\"\"\"\n    for msg in messages:\n        if not msg.strip():\n            raise ValueError(\"空のメッセージが含まれています\")\n```\n\nこの関数は、各メッセージ `msg` に対して `str.strip()` メソッドを使用して前後の空白文字を取り除き、結果が空の文字列かどうかを確認しています。空の文字列が見つかった場合は、 `ValueError` 例外が送出されます。\n\n使用例:\n\n```python\nmessages = [\"Hello\", \"   \", \"World\"]\nensure_no_empty_messages(messages)\n# ValueError: 空のメッセージが含まれています\n```\n                try:\n                    client.create_event(\n                        memory_id=memory_id,\n                        actor_id=actor_id,\n                        session_id=session_id,\n                        messages=conversation\n                    )\n                except Exception as e:\n                    print(f\"Error saving conversation: {str(e)}\")\n        \n        # Append response to full message history\n\n応答を完全なメッセージ履歴に追加します。\n        return {\"messages\": raw_messages + [response]}\n    \n    # グラフを作成する\n\nimport networkx as nx\n\nG = nx.Graph()\n\n# 頂点を追加する\nG.add_nodes_from([1, 2, 3])\n\n# エッジを追加する\nG.add_edges_from([(1, 2), (1, 3), (2, 3)])\n\n# 頂点の位置を設定する\npos = {1: (0, 0), 2: (1, 1), 3: (-1, 1)}\n\n# グラフを描画する\nnx.draw(G, pos, with_labels=True)\n    graph_builder = StateGraph(MessagesState)\n    \n    # ノードを追加する\n\n日本語訳:\n\n以下のテキストを英語から日本語に翻訳します。半角英数字の前後には半角スペースを挿入し、コード、コマンド、変数名、関数名などの技術的な用語はそのまま残します。\n\n`kubectl get nodes` を実行して、クラスターの現在のノードを確認します。出力は次のようになります。\n\n```\nNAME                                STATUS   ROLES    AGE   VERSION\ndocker-for-desktop                 Ready    master   84d   v1.24.0\n```\n\n新しいノードを追加するには、`kind create cluster --name=my-cluster --config=kind-config.yaml` を実行します。ここで、`kind-config.yaml` は次のようになります。\n\n```yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\n```\n\nこの設定では、1 つのコントロールプレーンノードと 2 つのワーカーノードを持つクラスターが作成されます。\n\nノードが正常に作成されたら、`kubectl get nodes` を再度実行すると、次のような出力が表示されます。\n\n```\nNAME                      STATUS   ROLES           AGE   VERSION\nmy-cluster-control-plane  Ready    control-plane   51s   v1.24.0\nmy-cluster-worker         Ready    worker          27s   v1.24.0  \nmy-cluster-worker2        Ready    worker          27s   v1.24.0\n```\n\nこれで、新しいノードが追加されたことがわかります。\n    graph_builder.add_node(\"chatbot\", chatbot)\n    graph_builder.add_node(\"tools\", ToolNode(tools))\n    \n    # Add edges\n\ngraph.add_edge(' 1 ', ' 2 ', weight=' 7 ')\ngraph.add_edge(' 1 ', ' 3 ', weight=' 9 ')\ngraph.add_edge(' 1 ', ' 6 ', weight=' 14 ')\ngraph.add_edge(' 2 ', ' 3 ', weight=' 10 ')\ngraph.add_edge(' 2 ', ' 4 ', weight=' 15 ')\ngraph.add_edge(' 3 ', ' 4 ', weight=' 11 ')\ngraph.add_edge(' 3 ', ' 6 ', weight=' 2 ')\ngraph.add_edge(' 4 ', ' 5 ', weight=' 6 ')\ngraph.add_edge(' 5 ', ' 6 ', weight=' 9 ')\n    graph_builder.add_conditional_edges(\n        \"chatbot\",\n        tools_condition,\n    )\n    graph_builder.add_edge(\"tools\", \"chatbot\")\n    \n    # Set entry point\n\nエントリポイントを設定します。\n\nENTRYPOINT [ \"python3\" ]\n\n日本語訳:\n\n# エントリポイントを設定します\n\nENTRYPOINT [ \"python3\" ]\n    graph_builder.set_entry_point(\"chatbot\")\n    \n    # グラフをコンパイルする\n\n日本語訳:\n\nコンパイラ = tf.lite.TFLiteConverter.from_saved_model(\"model.tflite\")\nコンパイラ.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\ntflite_model = コンパイラ.convert()\n\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"TFLite モデルが model.tflite に変換されました。\")\n    return graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929386fc-542f-49c9-9541-daeac8f32348",
   "metadata": {},
   "source": [
    "### エージェントの呼び出しのためのラッパーを作成する\n\nエージェントを呼び出すための簡単なラッパーを作成しましょう:\n\n日本語訳:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f87e0-a547-448b-9ef9-b416351c9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langgraph_bedrock(payload, agent):\n    以下が日本語訳になります。\n\n\"\"\"\n agent に payload を渡して実行する\n\"\"\"\n    user_input = payload.get(\"prompt\")\n    \n    # Create the input in the format expected by LangGraph\n\nLangGraph が期待する形式で入力を作成します。\n\n半角英数字の前後には半角スペースを挿入します。 コード、 コマンド、 変数名、 関数名などの技術的な用語は翻訳せず、そのまま残します。\n    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n    \n    # Extract the final message content\n\n最終的なメッセージの内容を抽出します。\n\nmessage_content = message.content\n\nif message.reference is not None:\n    # This is a reply\n    original_message = await message.channel.fetch_message(message.reference.message_id)\n    message_content = f\"Reply to {original_message.author.display_name}: {message_content}\"\n    return response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43528c42-384a-4822-970b-929875d50757",
   "metadata": {},
   "source": [
    "## ステップ 4: LangGraph エージェントの実行\n私たちは今、AgentCore Memory 統合を使ってエージェントを実行することができます。\n\nAgentCore Memory 統合を使って、 LangGraph エージェントを実行できます。\n\n以下のように、半角英数字の前後に半角スペースを挿入し、コード、コマンド、変数名、関数名などの技術的な用語はそのまま残しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beeaaea-5e84-483a-aea5-a31e7e2b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique actor and session IDs for this conversation\n\nこの会話のために一意のアクターIDとセッションIDを作成します。\n\nactor_id = \" 3c7db3c5-e1d3-41c7-b236-2484c0a5ed3b \"\nsession_id = \" 1518e8a8-7ceb-4ff6-9aee-0d2e655e6687 \"\nactor_id = f\"user-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\nsession_id = f\"workout-{datetime.now().strftime('%Y%m%d%H%M%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2576d-88da-4b7c-bbe4-34f2bf97db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent with AgentCore Memory integration\n\n# AgentCore Memory 統合を使用してエージェントを作成します\n\n日本語訳:\n\nエージェントを AgentCore Memory 統合機能を使って作成します。 agent = Agent.create( memory=AgentMemory(memory_stream=\"https://memory.stream.domain.com\") ) print(agent.memory.get(\"name\")) # => \"Claude\" agent.memory.set(\"favorite_color\", \"blue\")\nagent = create_agent(client, memory_id, actor_id, session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22334455-6677-8899-aabb-ccddeeff0011",
   "metadata": {},
   "source": [
    "#### おめでとうございます! あなたのエージェントの準備ができました!!\n\n### エージェントをテストしましょう\n\nエージェントのメモリ機能をテストするために、エージェントとインタラクションしましょう:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5530d8-a22b-4086-85ec-63435bed9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = langgraph_bedrock({\"prompt\": \"Hello! This is my first day, I need a workout routine.\"}, agent)\n",
    "print(f\"Agent: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbccdd-eeff-0011-2233-445566778899",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = langgraph_bedrock({\"prompt\": \"I want to build muscle, looking for a biceps routine. I have some lower back problems.\"}, agent)\n",
    "print(f\"Agent: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988776655-4433-2211-0099-8877665544",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = langgraph_bedrock({\"prompt\": \"Can you give me three exercises with number of reps?\"}, agent)\n",
    "print(f\"Agent: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3c4d-5e6f-7g8h-9i0j-1k2l3m4n5o6p",
   "metadata": {},
   "source": [
    "### メモリの永続性のテスト\n\nAgentCore Memory 統合の力を本当に実証するために、新しいエージェントインスタンスを作成し、前の会話を思い出せるかどうかを確認しましょう。\n\n日本語訳:\n### メモリの永続性のテスト\n\nAgentCore Memory 統合の力を本当に実証するために、新しい agent インスタンスを作成し、前の会話を思い出せるかどうかを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1w2e3r4t5y6-u7i8o9p0-a1s2d3f4-g5h6j7k8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいエージェントインスタンスを作成する (新しいセッションをシミュレートする)\n\n日本語訳:\n\n新しい agent インスタンスを作成します (新しいセッションをシミュレートします)。\nnew_agent = create_agent(client, memory_id, actor_id, session_id)\n\n# 新しいエージェントが私たちの設定を覚えているかテストする\n\n日本語訳:\n\n# Test if the new agent remembers our preferences\n\nこちらが英語から日本語への翻訳になります。\n\n技術的な用語である `# Test if the new agent remembers our preferences` はそのまま残しました。半角英数字の前後には半角スペースを挿入しています。\nresponse = langgraph_bedrock({\n    \"prompt\": \"Hello again! Can you remind me about my last workout session?\"\n}, new_agent)\n\nprint(\"New Agent Session:\\n\")\nprint(f\"Agent: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1x2c3v4b5n6m7-8k9j0h1g2-f3d4s5a6-p7o8i9u0",
   "metadata": {},
   "source": [
    "## 概要\n\nこのノートブックでは、以下のことを実演しました。\n\n1. AI エージェントの AgentCore Memory リソースを作成する方法\n2. メモリ統合を備えた LangGraph ワークフローを構築する方法\n3. 会話履歴の取得のためのメモリツールを実装する方法\n4. 必要に応じてメモリを賢明に使用するエージェントを作成する方法\n5. エージェントのインスタンス間でメモリの永続性をテストする方法\n\nこの統合は、構造化されたワークフロー (LangGraph) と堅牢なメモリシステム (AgentCore Memory) を組み合わせることで、より賢くコンテキストを認識できる AI エージェントを作成する力を示しています。\n\n私たちが実演したアプローチは、マルチエージェントシステム、抽出戦略を備えた長期メモリ、会話コンテキストに基づく特殊なメモリ検索など、より複雑なユースケースに拡張することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d2a15-3af9-4a07-94b6-f7d39e0fa038",
   "metadata": {},
   "source": [
    "## リソースの解放\nこのノートブックで使用したリソースを解放するため、メモリを削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3893ef-f6c3-4744-9860-ff15e014943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_memory_and_wait(memory_id = memory_id, max_wait = 300, poll_interval =10)\n\n日本語訳:\n\nクライアント側で memory_id で指定されたメモリを削除し、最大 300 秒間待機します。poll_interval は、削除の完了状況を確認する間隔(秒)を指定します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}