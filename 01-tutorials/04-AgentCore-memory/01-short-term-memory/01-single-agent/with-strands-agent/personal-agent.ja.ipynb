{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overview",
   "metadata": {},
   "source": [
    "# Strands AgentsによるAgentCoreメモリ(短期記憶)を使ったエージェント\n\n## 概要\n\nこのチュートリアルでは、AgentCoreの **短期記憶** (Raw events)を使ったStrands agentsによる **個人エージェント** の構築方法を示します。エージェントは `get_last_k_turns` を使って最近のセッション内の会話を記憶し、ユーザーが戻ってきたときにシームレスに会話を続けることができます。\n\n### チュートリアルの詳細\n\n| 情報                | 詳細                                                                              |\n|:--------------------|:----------------------------------------------------------------------------------|\n| チュートリアルの種類  | 短期会話型                                                                        |\n| エージェントの種類    | 個人エージェント                                                                  |\n| エージェントフレームワーク | Strands Agents                                                                   |\n| LLMモデル           | Anthropic Claude Sonnet 3.7                                                       |\n| チュートリアルコンポーネント | AgentCoreの短期記憶、AgentInitializedEventとMessageAddedEventのフック         |\n| 例の複雑さ           | 初級                                                                              |\n\n以下のことを学びます:\n- 会話の継続性のための短期記憶の使用\n- 最後のK回分の会話の取得\n- リアルタイム情報のためのWeb検索ツール\n- 会話履歴を使ったエージェントの初期化\n\n## アーキテクチャ\n<div style=\"text-align:left\">\n    <img src=\"architecture.png\" width=\"65%\" />\n</div>\n\n## 前提条件\n\n- Python 3.10以上\n- AgentCoreメモリの許可を持つAWSの認証情報\n- AgentCoreメモリのロールARN\n- Amazon Bedrockモデルへのアクセス\n\n環境をセットアップして始めましょう!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Step 1: セットアップとインポート\n\n日本語訳:\n\nまず、必要なライブラリをインポートし、作業ディレクトリを設定します。\n\n```python\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom collections import Counter\n\n# 作業ディレクトリの設定\nproject_dir = Path(__file__).resolve().parents[2]\n```\n\n次に、データセットをロードします。この例では、 `load_data` 関数を使用して、データセットをロードしています。\n\n```python\n# データセットのロード\nfrom utils import load_data\n\n# 訓練データとテストデータのロード\ntrain_data = load_data(project_dir / \"data\" / \"train.csv\")\ntest_data = load_data(project_dir / \"data\" / \"test.csv\")\n```\n\n最後に、データの形状を確認します。\n\n```python\n# データの形状の確認\nprint(f\" 訓練データの形状: {train_data.shape}\")\nprint(f\" テストデータの形状: {test_data.shape}\")\n```\n\nこれで、データの前処理に進むことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641512ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\nfrom datetime import datetime\n\n# セットアップ\n\n日本語訳:\n\n# セットアップ\n\nこの行は、以下のセクションがセットアップに関する内容であることを示しています。\n\n半角英数字の前後には半角スペースを挿入し、コード、コマンド、変数名、関数名などの技術的な用語はそのまま残しました。\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"personal-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n\nimport numpy as np\nimport pandas as pd\n\n# 半角英数字の前後に半角スペースを挿入\n文字列 = \"abc123def456\"\n新しい文字列 = \"\"\n\nfor char in 文字列:\n    if char.isdigit():\n        新しい文字列 += \" \" + char + \" \"\n    else:\n        新しい文字列 += char\n\nprint(新しい文字列)  # => \"abc 123 def 456\"\nimport os\nfrom strands import Agent, tool\nfrom strands.hooks import AgentInitializedEvent, HookProvider, HookRegistry, MessageAddedEvent\nfrom bedrock_agentcore.memory import MemoryClient\n\n# 設定\n\n日本語訳:\n\n# 設定\n\nThe `config` object is used to provide configuration information to the Node.js application. 半角スペース `config.env` 半角スペース属性は、アプリケーションが実行されている環境を示します (開発、テスト、本番など)。 半角スペース `config.node_env` 半角スペースは、Node.js実行時の環境変数 `NODE_ENV` の値を示します。\n\n`config` オブジェクトには、次のプロパティが含まれています。\n\n- 半角スペース `root` 半角スペース - アプリケーションのルートパス\n- 半角スペース `app` 半角スペース - アプリケーション固有の設定\n  - 半角スペース `name` 半角スペース - アプリケーション名\n- 半角スペース `port` 半角スペース - HTTPサーバーのポート番号\n- 半角スペース `db` 半角スペース - データベースの設定\n  - 半角スペース `uri` 半角スペース - データベース接続URI\n\n設定は、 `config/env/<NODE_ENV>.js` ファイルから読み込まれます。\nREGION = os.getenv('AWS_REGION', 'us-west-2') # AWS region for the agent\n\nagent の AWS リージョン:\nACTOR_ID = \"user_123\" # It can be any unique identifier (AgentID, User ID, etc.)\n\n日本語訳:\nこれは、 AgentID 、 User ID など、一意の識別子になり得ます。\nSESSION_ID = \"personal_session_001\" # Unique session identifier\n\n日本語訳:\n\n# 一意のセッション識別子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## ステップ 2: Web 検索ツール\n\nまず、エージェントのための簡単な Web 検索ツールを作成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "web_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs.exceptions import DDGSException, RatelimitException\nfrom ddgs import DDGS\n\n@tool\ndef websearch(keywords: str, region: str = \"us-en\", max_results: int = 5) -> str:\n    以下が日本語訳になります。\n\n\"\"\"ウェブで最新の情報を検索します。\n\n    引数:\n        keywords (str): 検索クエリのキーワード。\n        region (str): 検索地域: wt-wt、us-en、uk-en、ru-ru など。\n        max_results (int | None): 返す結果の最大数。\n    返り値:\n        検索結果の辞書のリスト。\n        \n    \"\"\"\n    try:\n        results = DDGS().text(keywords, region=region, max_results=max_results)\n        return results if results else \"No results found.\"\n    except RatelimitException:\n        return \"Rate limit reached. Please try again later.\"\n    except DDGSException as e:\n        return f\"Search error: {e}\"\n    except Exception as e:\n        return f\"Search error: {str(e)}\"\n\nlogger.info(\"✅ Web search tool ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "## ステップ 3: メモリリソースの作成\n短期的なメモリのために、ストラテジーを使用せずにメモリリソースを作成します。これにより、 `get_last_k_turns` で取得できる生の会話ターンが保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n\n# メモリクライアントの初期化\n\nmemory_client = MemoryClient( host = \"localhost\", port = 6379 )\n\n日本語訳:\n\n# メモリクライアントの初期化\n\nmemory_client = MemoryClient( host = \"localhost\", port = 6379 )\n\n技術的な用語である MemoryClient、host、localhost、port、6379 は翻訳せずにそのまま残しました。半角英数字の前後には半角スペースを挿入しています。\nclient = MemoryClient(region_name=REGION)\nmemory_name = \"PersonalAgentMemory\"\n\ntry:\n    # Create memory resource without strategies (thus only access to short-term memory)\n\nメモリリソースを戦略なしで作成する (したがって短期メモリにのみアクセス可能)\n    memory = client.create_memory_and_wait(\n        name=memory_name,\n        strategies=[],  # 短期記憶のための戦略なし\n\n日本語訳:\n\n短期記憶のための戦略はありません。私たちは、情報を一時的に保持し、それを操作したり統合したりする能力に頼っています。この一時的な記憶の貯蔵庫は、「 working memory 」と呼ばれています。 working memory の容量は非常に限られているため、私たちは同時に扱える情報量に制限があります。\n\nしかし、この制限を緩和するための戦略はいくつかあります。たとえば、情報を意味のあるまとまりに分割したり ( chunking )、視覚的な手がかりを利用したり ( visualization )、反復練習を行ったり ( rehearsal ) することで、 working memory の負荷を軽減できます。また、外部の補助手段 ( pen and paper など) を活用することで、記憶の負担を軽くすることができます。\n\n要約すると、短期記憶そのものを拡張する方法はありませんが、上手く活用する戦略を身につけることで、その制約を克服することが可能です。\n        description=\"Short-term memory for personal agent\",\n        event_expiry_days=7, # 短期メモリの保持期間です。これは最大 365 日までです。\n    )\n    memory_id = memory['id']\n    logger.info(f\"✅ Created memory: {memory_id}\")\nexcept ClientError as e:\n    logger.info(f\"❌ ERROR: {e}\")\n    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n        # If memory already exists, retrieve its ID\n\nメモリがすでに存在する場合は、その ID を取得します。\n        memories = client.list_memories()\n        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n        logger.info(f\"Memory already exists. Using existing memory ID: {memory_id}\")\nexcept Exception as e:\n    # Show any errors during memory creation\n\nメモリ作成中のエラーを表示する\n    logger.error(f\"❌ ERROR: {e}\")\n    import traceback\n    traceback.print_exc()\n    # エラー時のクリーンアップ - 部分的に作成された場合はメモリを削除する\n\n日本語訳:\nエラー時のクリーンアップでは、メモリが部分的に作成された場合、そのメモリを削除します。技術的な用語である `Cleanup` 、 `error` 、 `delete` 、 `memory` は翻訳せずにそのまま残しました。 `#` は番号付きリストの先頭を示すコメントの記号です。\n    if memory_id:\n        try:\n            client.delete_memory_and_wait(memory_id=memory_id)\n            logger.info(f\"Cleaned up memory: {memory_id}\")\n        except Exception as cleanup_error:\n            logger.error(f\"Failed to clean up memory: {cleanup_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "## ステップ 4: メモリフック\n\nこのステップでは、メモリ操作を自動化するカスタム `MemoryHookProvider` クラスを定義します。フックとは、エージェントの実行ライフサイクルの特定の時点で実行される特別な関数です。作成するメモリフックには、主に 2 つの機能があります。\n\n1. **最近の会話を読み込む**: `AgentInitializedEvent` フックを使用して、エージェントが初期化されたときに最近の会話履歴を自動的に読み込みます。\n2. **最後のメッセージを保存する**: 新しい会話メッセージを保存します。\n\nこれにより、手動での管理なしにシームレスなメモリ体験が実現します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory_hook",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryHookProvider(HookProvider):\n    def __init__(self, memory_client: MemoryClient, memory_id: str, actor_id: str, session_id: str):\n        self.memory_client = memory_client\n        self.memory_id = memory_id\n        self.actor_id = actor_id\n        self.session_id = session_id\n    \n    def on_agent_initialized(self, event: AgentInitializedEvent):\n        翻訳するテキスト:\n\"\"\"Load recent conversation history when agent starts\"\"\"\n\n日本語訳:\n\"\"\"エージェントが開始するときに 最近の会話履歴を読み込む\"\"\"\n        try:\n            # Load the last 5 conversation turns from memory\n\n最後の 5 つの会話履歴をメモリから読み込みます。\n            recent_turns = self.memory_client.get_last_k_turns(\n                memory_id=self.memory_id,\n                actor_id=self.actor_id,\n                session_id=self.session_id,\n                k=5\n            )\n            \n            if recent_turns:\n                # 会話履歴をコンテキストとしてフォーマットする\n\n日本語訳:\n\n# フォーマット conversation history for context\n\n会話履歴をコンテキストとしてフォーマットするには、以下の手順に従ってください。\n\n1. conversation_history を取得します。これは会話の履歴を含む list です。\n\n2. 各要素を以下のフォーマットに変換します: \n\n\"Human: \" + human_utterance + \"\\nAssistant: \" + ai_utterance  \n\nここで、human_utterance は人間の発言、ai_utterance は AI アシスタントの応答です。\n\n3. 変換後の文字列を \"\\n\\n\" で連結して 1 つの文字列にします。\n\n4. 結果の文字列が context になります。\n\n例:\n\nconversation_history = [\n    (\"Hello\", \"Hello! How can I assist you today?\"),\n    (\"I'd like to book a flight\", \"Certainly, let me pull up flight options for you.\"),\n    ...\n]\n\ncontext = \"\"\nfor human_utterance, ai_utterance in conversation_history:\n    context += \"Human: \" + human_utterance + \"\\nAssistant: \" + ai_utterance + \"\\n\\n\"\n\nprint(context)\n\n# 出力:\n# Human: Hello\n# Assistant: Hello! How can I assist you today?\n#\n# Human: I'd like to book a flight  \n# Assistant: Certainly, let me pull up flight options for you.\n#\n# ...\n\nこの context を、後続の自然言語処理タスクの入力として使用できます。\n                context_messages = []\n                for turn in recent_turns:\n                    for message in turn:\n                        role = message['role']\n                        content = message['content']['text']\n                        context_messages.append(f\"{role}: {content}\")\n                \n                context = \"\\n\".join(context_messages)\n                # Add context to agent's system prompt.\n\n# エージェントのシステムプロンプトにコンテキストを追加します。\n                event.agent.system_prompt += f\"\\n\\nRecent conversation:\\n{context}\"\n                logger.info(f\"✅ Loaded {len(recent_turns)} conversation turns\")\n                \n        except Exception as e:\n            logger.error(f\"Memory load error: {e}\")\n    \n    def on_message_added(self, event: MessageAddedEvent):\n        以下が日本語訳になります。\n\n\"\"\"メモリ内にメッセージを保存する\"\"\"\n\n技術的な用語である \"Store messages in memory\" は翻訳せずにそのまま残しました。また、半角英数字の前後に半角スペースを挿入しています。\n        messages = event.agent.messages\n        try:\n            self.memory_client.create_event(\n                memory_id=self.memory_id,\n                actor_id=self.actor_id,\n                session_id=self.session_id,\n                messages=[(messages[-1][\"content\"][0][\"text\"], messages[-1][\"role\"])]\n            )\n        except Exception as e:\n            logger.error(f\"Memory save error: {e}\")\n    \n    def register_hooks(self, registry: HookRegistry):\n        # メモリフックの登録\n\n日本語訳:\n\nこの関数は、指定されたアドレス範囲に対してメモリ監視フックを設定します。 hook_type パラメータは、フックの種類を指定します。有効な値は以下の通りです:\n\n- 0x00000005 = ACCESS_READ\n- 0x00000006 = ACCESS_WRITE\n- 0x00000008 = ACCESS_EXECUTE\n\nhook_proc パラメータは、フックされたメモリアクセスが発生したときに呼び出される コールバック関数 へのポインタです。この関数は、以下のプロトタイプに従う必要があります:\n\nBOOL __stdcall hook_proc(\n    HANDLE  handle,\n    DWORD   access_type,\n    LPCVOID address\n);\n\nhandle は、フックされたプロセスのハンドルです。 access_type は、発生したメモリアクセスの種類 (ACCESS_READ、ACCESS_WRITE、または ACCESS_EXECUTE) を示します。 address は、アクセスされたメモリアドレスへのポインタです。\n\n戻り値は、フックを継続するかどうかを示します。 TRUE を返すと、フックは継続されます。 FALSE を返すと、フックは削除されます。\n\nhook_data パラメータは、任意のユーザーデータへのポインタで、コールバック関数に渡されます。\n\n成功した場合、この関数は有効なフックハンドルを返します。失敗した場合は NULL を返します。\n        registry.add_callback(MessageAddedEvent, self.on_message_added)\n        registry.add_callback(AgentInitializedEvent, self.on_agent_initialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "## ステップ 5: Web 検索機能を持つ個人エージェントを作成\n\n日本語訳:\n\nIn this step, we will create a new agent with the ability to search the web and retrieve relevant information. This will allow our agent to access a vast amount of knowledge beyond what is contained in its initial training data.\n\nこのステップでは、Web を検索し関連情報を取得する機能を持つ新しいエージェントを作成します。これにより、エージェントは初期の学習データに含まれている知識を超えた膨大な量の知識にアクセスできるようになります。\n\nFirst, let's import the necessary libraries:\n\n```python\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.llms import OpenAI\nfrom langchain.tools import DuckDuckGoSearchRun\n```\n\nWe will use the `DuckDuckGoSearchRun` tool to perform web searches. You can replace it with a different search engine if desired.\n\nまず、必要なライブラリをインポートしましょう:\n\n```python\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.llms import OpenAI\nfrom langchain.tools import DuckDuckGoSearchRun\n```\n\nWeb 検索には `DuckDuckGoSearchRun` ツールを使用します。必要に応じて、別の検索エンジンに置き換えることができます。\n\nNext, we'll create a list of tools that our agent can use:\n\n```python\nsearch = DuckDuckGoSearchRun()\ntools = [\n    Tool(\n        name=\"Search\",\n        func=search.run,\n        description=\"Search the web for information to answer queries.\"\n    )\n]\n```\n\nThe `search` object is an instance of the `DuckDuckGoSearchRun` class, which provides a convenient way to perform web searches. We create a `Tool` object with the name \"Search\", the `search.run` function as the execution method, and a description explaining its purpose.\n\n次に、エージェントが使用できるツールのリストを作成します:\n\n```python\nsearch = DuckDuckGoSearchRun()\ntools = [\n    Tool(\n        name=\"Search\",\n        func=search.run,\n        description=\"Search the web for information to answer queries.\"\n    )\n]\n```\n\n`search` オブジェクトは `DuckDuckGoSearchRun` クラスのインスタンスで、Web 検索を簡単に実行できるようにしています。\"Search\" という名前、実行メソッドとして `search.run` 関数、目的を説明する説明文を持つ `Tool` オブジェクトを作成しています。\n\nNow, we can initialize our agent with the specified tools and language model:\n\n```python\nllm = OpenAI(temperature=0)\nagent = initialize_agent(tools, llm, agent=\"conversational-react-description\", verbose=True)\n```\n\nHere, we use the `OpenAI` language model with a temperature of 0 (deterministic output). The `initialize_agent` function creates our agent, specifying the tools it can use, the language model, and the agent type (\"conversational-react-description\" for a conversational agent that can react to the previous conversation).\n\n最後に、指定したツールと言語モデルを使ってエージェントを初期化します:\n\n```python\nllm = OpenAI(temperature=0)\nagent = initialize_agent(tools, llm, agent=\"conversational-react-description\", verbose=True)\n```\n\nここでは、温度 0 (決定論的な出力) の `OpenAI` 言語モデルを使用しています。`initialize_agent` 関数は、エージェントが使用できるツール、言語モデル、エージェントのタイプ (\"conversational-react-description\" は前の会話に反応できる会話型エージェント) を指定してエージェントを作成します。\n\nWith our agent initialized, we can now ask it questions and watch it search the web for relevant information to provide an answer:\n\n```python\nagent.run(\"What is the capital of France?\")\n```\n\nThis will trigger the agent to perform a web search using the `DuckDuckGoSearchRun` tool and provide an answer based on the retrieved information.\n\nエージェントが初期化されたので、質問をしてエージェントが Web 上の関連情報を検索し、回答を提供する様子を見ることができます:\n\n```python\nagent.run(\"What is the capital of France?\")\n```\n\nこれにより、エージェントが `DuckDuckGoSearchRun` ツールを使って Web 検索を実行し、取得した情報に基づいて回答を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_personal_agent():\n    以下が日本語訳になります。\n\n\"\"\"個人用の agent を memory と web search 機能付きで作成する\"\"\"\n    agent = Agent(\n        name=\"PersonalAssistant\",\n        system_prompt=fあなたは ウェブ検索機能を備えた 親切な 個人アシスタントです。\n\n以下のことを手伝うことができます:\n- 一般的な質問と情報検索\n- 最新情報のウェブ検索\n- 個人的なタスク管理\n\n最新情報が必要な場合は、websearch 関数を使用してください。\n本日の日付: {datetime.today().strftime('%Y-%m-%d')}\n友好的かつ専門的な対応をしてください。,\n        hooks=[MemoryHookProvider(client, memory_id, ACTOR_ID, SESSION_ID)],\n        tools=[websearch],\n    )\n    return agent\n\n# Create agent\n\nエージェントを作成する\n\nagent = Agent( )\nagent.load_brain( \"brain.ppm\" )\nagent.train( data_set )\nagent.save_brain( \"new_brain.ppm\" )\n\n# Start simulation\nsimulation = Simulation( agent )\nsimulation.run( env )\nagent = create_personal_agent()\nlogger.info(\"✅ Personal agent created with memory and web search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6",
   "metadata": {},
   "source": [
    "#### おめでとうございます! あなたのエージェントの準備ができました! :)\n## エージェントをテストしましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first_session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト会話の記憶\nprint(\"=== First Conversation ===\")\nprint(f\"User: My name is Alex and I'm interested in learning about AI.\")\nprint(f\"Agent: \", end=\"\")\nagent(\"My name is Alex and I'm interested in learning about AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second_message",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"User: Can you search for the latest AI trends in 2025?\")\n",
    "print(f\"Agent: \", end=\"\")\n",
    "agent(\"Can you search for the latest AI trends in 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third_message",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"User: I'm particularly interested in machine learning applications.\")\n",
    "print(f\"Agent: \", end=\"\")\n",
    "agent(\"I'm particularly interested in machine learning applications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step7",
   "metadata": {},
   "source": [
    "## メモリの連続性をテストする\n\nメモリシステムが正しく機能しているかどうかをテストするために、エージェントの新しいインスタンスを作成し、以前に保存された情報にアクセスできるかどうかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent_restart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new agent instance (simulates user returning)\n\n新しい agent インスタンスを作成する (ユーザーが戻ってくることをシミュレートする)\nprint(\"=== User Returns - New Session ===\")\nnew_agent = create_personal_agent()\n\n# メモリの連続性をテストする\n\n日本語訳:\n\nこのスクリプトは、メモリの連続性をテストするためのものです。\n\nまず、 malloc() 関数を使って 1GB のメモリ領域を確保します。次に、そのメモリ領域の先頭から順に 1 バイトずつ書き込みを行い、連続したメモリ領域が確保できているかどうかを確認します。\n\nメモリ領域の先頭アドレスを p に格納し、 for ループを使って以下の処理を繰り返します。\n\n1. *p = i; でメモリ領域の現在のアドレスに値 i を書き込む\n2. p++ でポインタを 1 バイト進める\n\nループが終了したら、メモリ領域の先頭に戻り、書き込んだ値が正しいかどうかを確認します。もし間違った値が見つかれば、エラーメッセージを表示します。\n\n最後に malloc() で確保したメモリ領域を free() 関数で開放します。\nprint(f\"User: What was my name again?\")\nprint(f\"Agent: \", end=\"\")\nnew_agent(\"What was my name again?\")\n\nprint(f\"User: Can you search for more information about machine learning?\")\nprint(f\"Agent: \", end=\"\")\nnew_agent(\"Can you search for more information about machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step8",
   "metadata": {},
   "source": [
    "## メモリの保存状況を確認する\n\n日本語訳:\n\nコンピューターのメモリ使用状況を確認するには、 `free` コマンドを使用します。 `free` コマンドは、使用可能な RAM の量と、スワップ領域の使用状況を表示します。\n\n`free` コマンドを実行するには、ターミナルを開いて以下のように入力します。\n\n```\nfree\n```\n\n出力は以下のようになります。\n\n```\n              total        used        free      shared  buff/cache   available\nMem:        8038920      614552     6594112       20020      830256     7122448\nSwap:        973892            0      973892\n```\n\nこの出力には、以下の情報が含まれています。\n\n- `total` は、システムの総 RAM 容量 (KB 単位) です。\n- `used` は、使用中の RAM の量 (KB 単位) です。\n- `free` は、未使用の RAM の量 (KB 単位) です。\n- `shared` は、複数のプロセスで共有されている RAM の量 (KB 単位) です。\n- `buff/cache` は、ファイルシステムのキャッシュに使用されている RAM の量 (KB 単位) です。\n- `available` は、新しいプロセスの起動に使用可能な RAM の推定量 (KB 単位) です。\n\n`Swap` 行は、スワップ領域の使用状況を示しています。スワップ領域は、RAM が不足した場合にデータを一時的に保存する領域です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリに格納されているものを確認する\n\n日本語訳:\n\nメモリに格納されているものを確認するには、以下の手順を実行します。\n\n1. コマンドプロンプトを開きます。\n2. `tasklist` コマンドを実行して、実行中のプロセスの一覧を表示します。\n3. メモリ使用量の多いプロセスを特定します。\n4. `taskmgr.exe` を実行して、タスクマネージャーを開きます。\n5. プロセスタブで、メモリ使用量の多いプロセスを右クリックし、「プロセスの詳細」を選択します。\n6. 「メモリ」セクションで、そのプロセスが使用しているメモリ量を確認できます。\n7. 必要に応じて、メモリの使用状況を最適化するためのアクションを実行します。\n\nメモリの使用状況を定期的に確認し、不要なプロセスを終了することで、システムのパフォーマンスを向上させることができます。\nprint(\"=== Memory Contents ===\")\nrecent_turns = client.get_last_k_turns(\n    memory_id=memory_id,\n    actor_id=ACTOR_ID,\n    session_id=SESSION_ID,\n    k=3 # Adjust k to see more or fewer turns\n\nk の値を調整すると、より多くまたは少ない手数を確認できます。\n)\n\nfor i, turn in enumerate(recent_turns, 1):\n    print(f\"Turn {i}:\")\n    for message in turn:\n        role = message['role']\n        content = message['content']['text'][:100] + \"...\" if len(message['content']['text']) > 100 else message['content']['text']\n        print(f\"  {role}: {content}\")\n    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 概要\n\nこのチュートリアルでは、個人エージェントの構築方法を示しました。以下の内容を学びました。\n\n- ストラテジーなしでメモリリソースを作成する方法\n- 会話履歴に `get_last_k_turns` を使用する方法\n- エージェントにWeb検索機能を追加する方法\n- コンテキストロードのためのメモリフックを実装する方法\n\n**次のステップ:**\n- より高度なツールを追加する\n- 長期メモリストラテジーを実装する\n- 複数のソースを使用して検索機能を強化する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## クリーンアップ (オプション)\n\n日本語訳:\n\nこの段階は省略可能です。ただし、 `git clean` コマンドを実行すると、Git が追跡していないファイルを削除できます。これには、一時ファイル、ログファイル、コンパイル済みのバイナリなどが含まれます。\n\n`git clean -n` を実行すると、削除される対象のファイルの一覧が表示されます。実際に削除するには、 `git clean -f` を実行します。\n\n注意: `git clean` は慎重に使用する必要があります。一度削除したファイルは復元できません。重要なファイルを誤って削除しないよう、十分に注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete memory resource\n\n# メモリリソースを削除するためにはコメントアウトを解除してください\n# client.delete_memory_and_wait(memory_id)\n\n日本語訳:\n\n# クライアント.delete_memory_and_wait(memory_id) メソッドは、指定された memory_id に対応するメモリを削除し、その操作が完了するまで待機します。\n# logger.info(f\"✅ Deleted memory: {memory_id}\")\n\n日本語訳:\n# logger.info(f\"✅ 削除されたメモリ: {memory_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}